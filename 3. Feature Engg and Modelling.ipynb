{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "| Model | Mse |\n",
      "+-------+-----+\n",
      "+-------+-----+\n"
     ]
    }
   ],
   "source": [
    "tableData = PrettyTable()\n",
    "tableData.field_names = [\"Model\", \"Mse\"]\n",
    "print(tableData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16664, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./cleaned_features.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing: Stemming, stop-word removal and Lemmatization.\n",
    "\n",
    "Hence in the Preprocessing phase we do the following in the order below:-\n",
    "\n",
    "1. Begin by removing the html tags\n",
    "2. Remove any punctuations or limited set of special characters like , or . or # etc.\n",
    "3. Check if the word is made up of english letters and is not alpha-numeric\n",
    "4. Check to see if the length of the word is greater than 2 (as it was researched that there is no adjective in 2-letters)\n",
    "5. Convert the word to lowercase\n",
    "6. Remove Stopwords\n",
    "7. Finally Snowball Stemming the word (it was obsereved to be better than Porter Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10204\n",
      "<br />A lovely share apartment in Southfields! You will adore it! Our flat is perfect for solo adventurers, young professionals and students! n- Brightness and comfort n- Excellent location and connection n- Just refurbished n- 5 minutes walking distance from Earsfields Station<br /> We are happy to introduce you to our flat in the middle of Southfields. Our apartment has all you need to enjoy a great stay in the heart of Southwest of London. The place has five fully furnished bedroom and separate toilet and bathroom.  The kitchen is fully equipped and there is a lovely cosy dining area where you can enjoy a meal with your flat mates. You will love cooking here! Our new refurbished apartment has all you need to enjoy a great stay in London. We have decorated this flat with all our creativity, with colourful decorations and a touch of Scandinavian style. - Guests have unlimited access to all amenities and equipment in the flat.  - Please make yourself at home but treat the apartment as \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "i=0;\n",
    "for sent in df['description'].values:\n",
    "    if (len(re.findall('<.*?>', sent))):\n",
    "        print(i)\n",
    "        print(sent)\n",
    "        break;\n",
    "    i += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/raviranjan0631/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "{'they', \"isn't\", \"you'd\", 'ma', 'more', \"hasn't\", 've', 'in', 'his', 'is', 'were', 'other', 'a', \"shan't\", 'wasn', 'd', 'are', 'itself', 'theirs', 'do', 'off', 'she', 'being', 'both', \"hadn't\", 'myself', 'what', 'but', 'has', 'be', 'ourselves', 'until', 'on', 'than', 'doing', 'which', 'during', 'no', 'after', 'am', 'couldn', 'all', \"you've\", 'm', \"mustn't\", 'same', 'hers', 'them', 'an', 'mightn', \"wouldn't\", 'those', 'him', 'by', \"shouldn't\", 'shouldn', 'who', 'as', 'each', 'between', 'it', 'themselves', 'again', 'have', 'their', 'did', 'own', 'mustn', 'that', 'our', 'the', \"you'll\", 'your', 'haven', 'had', 'any', \"haven't\", 'further', 's', 'll', 'how', 'few', 'will', \"aren't\", 'weren', 'won', 'some', 'whom', 'once', 'too', 'we', 'under', 't', 'yourselves', 'down', 'himself', 'herself', 'yourself', 'at', 'up', 'isn', 'here', 'not', \"should've\", 'shan', \"won't\", 'he', 'for', 'while', 'yours', 'now', 'there', 'can', 'why', 'above', 'or', 'before', 'ours', \"it's\", 'out', 'then', 'its', 'through', 'very', 'nor', \"couldn't\", 'doesn', 'didn', \"you're\", 'should', 'with', \"didn't\", 'and', 'having', 'me', 'of', \"doesn't\", \"mightn't\", 'when', 'aren', 'her', 'just', \"weren't\", 'ain', 'to', 'into', 'from', 'i', 'because', 'this', 'where', 'such', \"wasn't\", 'hadn', 'wouldn', 'does', \"that'll\", 'about', 'y', 'so', 'most', 'was', 'don', 'been', 'only', 'these', 'if', 'hasn', 're', 'you', \"she's\", \"don't\", 'needn', 'my', 'against', 'below', 'o', \"needn't\", 'over'}\n",
      "************************************\n",
      "tasti\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned\n",
    "print(stop)\n",
    "print('************************************')\n",
    "print(sno.stem('tasty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code takes a while to run as it needs to run on 10k sentences.\n",
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "s=''\n",
    "for sent in df['description'].values:\n",
    "    filtered_sentence=[]\n",
    "    #print(sent);\n",
    "    sent=cleanhtml(sent) # remove HTMl tags\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "    #print(filtered_sentence)\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "    #print(\"***********************************************************************\")\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>price</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>extra_people</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lots of windows and light.  St Luke's Gardens ...</td>\n",
       "      <td>51.48796</td>\n",
       "      <td>-0.16898</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.73</td>\n",
       "      <td>lot window light luke garden end block river f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Open from June 2018 after a 3-year break, we a...</td>\n",
       "      <td>51.52098</td>\n",
       "      <td>-0.14002</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>300.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.41</td>\n",
       "      <td>open june break delight welcom guest superb mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big room with double bed/ clean sheets/ clean ...</td>\n",
       "      <td>51.57224</td>\n",
       "      <td>-0.20906</td>\n",
       "      <td>Others</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.08</td>\n",
       "      <td>big room doubl bed clean sheet clean towel cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Situated literally in London Fields park and o...</td>\n",
       "      <td>51.53972</td>\n",
       "      <td>-0.05885</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>80.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.48</td>\n",
       "      <td>situat liter london field park moment lido hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private lockable bedsit room available within ...</td>\n",
       "      <td>51.52589</td>\n",
       "      <td>-0.19942</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not Real bed</td>\n",
       "      <td>29.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.13</td>\n",
       "      <td>privat lockabl bedsit room avail within bright...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  latitude  longitude  \\\n",
       "0  Lots of windows and light.  St Luke's Gardens ...  51.48796   -0.16898   \n",
       "1  Open from June 2018 after a 3-year break, we a...  51.52098   -0.14002   \n",
       "2  Big room with double bed/ clean sheets/ clean ...  51.57224   -0.20906   \n",
       "3  Situated literally in London Fields park and o...  51.53972   -0.05885   \n",
       "4  Private lockable bedsit room available within ...  51.52589   -0.19942   \n",
       "\n",
       "  property_type        room_type  accommodates  bathrooms  bedrooms  beds  \\\n",
       "0     Apartment  Entire home/apt             2        1.0       1.0   1.0   \n",
       "1     Apartment  Entire home/apt             6        2.0       3.0   3.0   \n",
       "2        Others     Private room             2        1.5       1.0   1.0   \n",
       "3     Apartment  Entire home/apt             2        1.0       1.0   1.0   \n",
       "4     Apartment     Private room             2        1.0       1.0   1.0   \n",
       "\n",
       "       bed_type  price  cleaning_fee  guests_included  extra_people  \\\n",
       "0      Real Bed  100.0          50.0                2           0.0   \n",
       "1      Real Bed  300.0          65.0                4          10.0   \n",
       "2      Real Bed   29.0           0.0                1           8.0   \n",
       "3      Real Bed   80.0          30.0                1           0.0   \n",
       "4  Not Real bed   29.0          15.0                1          10.0   \n",
       "\n",
       "   minimum_nights  reviews_per_month  \\\n",
       "0               3               0.73   \n",
       "1               3               0.41   \n",
       "2              10               1.08   \n",
       "3               6               0.48   \n",
       "4               5               0.13   \n",
       "\n",
       "                                         CleanedText  \n",
       "0  lot window light luke garden end block river f...  \n",
       "1  open june break delight welcom guest superb mo...  \n",
       "2  big room doubl bed clean sheet clean towel cle...  \n",
       "3  situat liter london field park moment lido hea...  \n",
       "4  privat lockabl bedsit room avail within bright...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CleanedText']=final_string #adding a column of CleanedText which displays the data after pre-processing of the review \n",
    "df['CleanedText']=df['CleanedText'].str.decode(\"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tfidf vectors shape of data is  (16664, 23854)\n"
     ]
    }
   ],
   "source": [
    "## TF-IDF\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1,2),min_df = 10)\n",
    "tfidf = tf_idf.fit_transform(df['CleanedText'].values)\n",
    "print('The tfidf vectors shape of data is ',tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['description', 'latitude', 'longitude', 'property_type', 'room_type',\n",
       "       'accommodates', 'bathrooms', 'bedrooms', 'beds', 'bed_type', 'price',\n",
       "       'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights',\n",
       "       'reviews_per_month', 'CleanedText'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.price.values\n",
    "df = df.drop(['description', 'price', 'CleanedText'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 16664 rows, 18 columns.\n"
     ]
    }
   ],
   "source": [
    "# Dummy encoding\n",
    "categorical_feats = ['property_type', 'room_type', 'bed_type']\n",
    "df = pd.get_dummies(df, columns=categorical_feats, drop_first=False)\n",
    "print(\"Dataset has {} rows, {} columns.\".format(*df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column standarization\n",
    "df['accommodates'] = (df['accommodates'] - df['accommodates'].mean()) / df['accommodates'].std()\n",
    "df['bathrooms'] = (df['bathrooms'] - df['bathrooms'].mean()) / df['bathrooms'].std()\n",
    "df['bedrooms'] = (df['bedrooms'] - df['bedrooms'].mean()) / df['bedrooms'].std()\n",
    "df['cleaning_fee'] = (df['cleaning_fee'] - df['cleaning_fee'].mean()) / df['cleaning_fee'].std()\n",
    "df['minimum_nights'] = (df['minimum_nights'] - df['minimum_nights'].mean()) / df['minimum_nights'].std()\n",
    "df['extra_people'] = (df['extra_people'] - df['extra_people'].mean()) / df['extra_people'].std()\n",
    "df['beds'] = (df['beds'] - df['beds'].mean()) / df['beds'].std()\n",
    "df['guests_included'] = (df['guests_included'] - df['guests_included'].mean()) / df['guests_included'].std()\n",
    "df['reviews_per_month'] = (df['reviews_per_month'] - df['reviews_per_month'].mean()) / df['reviews_per_month'].std()\n",
    "\n",
    "\n",
    "df['tfidf'] = tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16664, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "seed = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 6314.74\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the testing set\n",
    "regr_y_pred = regr.predict(X_test)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, regr_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    " tableData.add_row([\"Linear Regression\", mean_squared_error(y_test, regr_y_pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning the model\n",
    "param_grid = { \"n_estimators\"      : [175, 200, 225, 250],\n",
    "           \"criterion\"         : ['mse'],\n",
    "           \"max_features\"      : ['auto'], #auto, sqrt, log2, int/n_feature\n",
    "           \"max_depth\"         : [10, 14, 15, 16, 18],\n",
    "           \"min_samples_split\" : [6, 7, 8, 9, 10] ,\n",
    "           \"bootstrap\": [True]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 33min 42s, sys: 10 s, total: 1h 33min 52s\n",
      "Wall time: 1h 34min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "rf_cv = GridSearchCV(rf, param_grid, cv=5)\n",
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 3982.48\n",
      "Variance score: 0.64\n",
      "Tuned Model Parameters: {'bootstrap': True, 'criterion': 'mse', 'max_depth': 18, 'max_features': 'auto', 'min_samples_split': 6, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "rf_y_pred = rf_cv.predict(X_test)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, rf_y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, rf_y_pred))\n",
    "# Best params\n",
    "print(\"Tuned Model Parameters: {}\".format(rf_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " tableData.add_row([\"Random Forest Regression\", mean_squared_error(y_test, rf_y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-------------------+\n",
      "|          Model           |        Mse        |\n",
      "+--------------------------+-------------------+\n",
      "|    Linear Regression     | 6314.743795004338 |\n",
      "| Random Forest Regression |  3982.47511449271 |\n",
      "+--------------------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "print(tableData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation \n",
    "\n",
    "We get minimum Mse in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
